{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(urls):\n",
    "    for url in urls:\n",
    "        df = pd.read_parquet(url)\n",
    "        yield df\n",
    "\n",
    "urls = [\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-01.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-02.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-03.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-04.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-05.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-06.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-07.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-08.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-09.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-10.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-11.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-12.parquet\"\n",
    "    # Add more URLs as needed\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "for df in load_data(urls):\n",
    "    load_info = pipeline.run(df, table_name=\"yellow_taxi\")\n",
    "    print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "\n",
    "# let's see the tables\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "print('Loaded tables: ')\n",
    "display(conn.sql(\"show tables\"))\n",
    "\n",
    "\n",
    "print(\"\\n\\n\\n Rides table below: Note the times are properly typed\")\n",
    "yellow_taxi = conn.sql(\"SELECT * FROM yellow_taxi LIMIT 10\").df()\n",
    "display(yellow_taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading yellow taxi data for 2019\n",
    "def load_data(urls):\n",
    "    for url in urls:\n",
    "        df = pd.read_parquet(url)\n",
    "        yield df\n",
    "\n",
    "urls = [\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-01.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-02.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-03.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-04.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-05.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-06.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-07.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-08.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-09.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-10.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-11.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-12.parquet\"\n",
    "    # Add more URLs as needed\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    #staging='filesystem',\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "for df in load_data(urls):\n",
    "    load_info = pipeline.run(df, loader_file_format=\"parquet\", table_name=\"yellow_taxi\")\n",
    "    print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading yellow taxi data for 2020\n",
    "def load_data(urls):\n",
    "    for url in urls:\n",
    "        df = pd.read_parquet(url)\n",
    "        yield df\n",
    "\n",
    "urls = [\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-01.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-02.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-03.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-04.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-05.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-06.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-07.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-08.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-09.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-10.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-11.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-12.parquet\"\n",
    "    # Add more URLs as needed\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    #staging='filesystem',\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "for df in load_data(urls):\n",
    "    load_info = pipeline.run(df, loader_file_format=\"parquet\", table_name=\"yellow_taxi\", write_disposition=\"append\")\n",
    "    print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading green taxi data for 2019\n",
    "def load_data(urls):\n",
    "    for url in urls:\n",
    "        df = pd.read_parquet(url)\n",
    "        yield df\n",
    "\n",
    "urls = [\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-01.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-02.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-03.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-04.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-05.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-06.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-07.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-08.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-09.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-10.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-11.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-12.parquet\"\n",
    "    # Add more URLs as needed\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    #staging='filesystem',\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "for df in load_data(urls):\n",
    "    load_info = pipeline.run(df, loader_file_format=\"parquet\", table_name=\"green_taxi\")\n",
    "    print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading green taxi data for 2020\n",
    "def load_data(urls):\n",
    "    for url in urls:\n",
    "        df = pd.read_parquet(url)\n",
    "        yield df\n",
    "\n",
    "urls = [\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-01.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-02.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-03.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-04.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-05.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-06.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-07.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-08.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-09.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-10.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-11.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2020-12.parquet\"\n",
    "    # Add more URLs as needed\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    #staging='filesystem',\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "for df in load_data(urls):\n",
    "    load_info = pipeline.run(df, loader_file_format=\"parquet\", table_name=\"green_taxi\", write_disposition=\"append\")\n",
    "    print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading fhv_tripdata data for 2019 one by one because of several problems with data. Look att next part.\n",
    "def load_data(urls):\n",
    "    for url in urls:\n",
    "        df = pd.read_parquet(url)\n",
    "        yield df\n",
    "\n",
    "urls = [\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-01.parquet\"\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-02.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-03.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-04.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-05.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-06.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-07.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-08.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-09.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-10.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-11.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-12.parquet\"\n",
    "    # Add more URLs as needed\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    #staging='filesystem',\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "for df in load_data(urls):\n",
    "    load_info = pipeline.run(df, loader_file_format=\"parquet\", table_name=\"fhv_tripdata_2019\")\n",
    "    print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading fhv_tripdata data for 2019 one by one because the data has probelm with Casting from timestamp[us] to timestamp[ns] and column p_ulocation_id existing type bigint and\n",
    "#it should be float\n",
    "def load_data(urls):\n",
    "    for url in urls:\n",
    "        df = pd.read_parquet(url)\n",
    "        yield df\n",
    "\n",
    "urls = [\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-01.parquet\"\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-02.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-03.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-04.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-05.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-06.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-07.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-08.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-09.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-10.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-11.parquet\",\n",
    "    #\"https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-12.parquet\"\n",
    "    # Add more URLs as needed\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    #staging='filesystem',\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "for df in load_data(urls):\n",
    "    load_info = pipeline.run(df, loader_file_format=\"parquet\", table_name=\"fhv_tripdata_2019\", write_disposition=\"append\")\n",
    "    print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "table = pq.read_table(\"/Users/nevenkalukic/code/dlt-workshop/fhv-tripdata-2019/fhv_tripdata_2019-06.parquet\")\n",
    "df_fhv = table.filter(\n",
    "    pc.less_equal(table[\"dropOff_datetime\"], pa.scalar(pd.Timestamp.max))\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    #staging='filesystem',\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "\n",
    "load_info = pipeline.run(df_fhv, loader_file_format=\"parquet\", table_name=\"fhv_tripdata_2019\", write_disposition=\"append\")\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_may = pd.read_parquet(\"/Users/nevenkalukic/code/dlt-workshop/fhv-tripdata-2019/fhv_tripdata_2019-05.parquet\")\n",
    "df_may.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_may.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_may['PUlocationID'] = pd.to_numeric(df_may['PUlocationID'], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_may['DOlocationID'] = pd.to_numeric(df_may['DOlocationID'], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_may.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    #staging='filesystem',\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "\n",
    "load_info = pipeline.run(df_may, loader_file_format=\"parquet\", table_name=\"fhv_tripdata_2019\", write_disposition=\"append\")\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jun = pd.read_parquet(\"/Users/nevenkalukic/code/dlt-workshop/fhv-tripdata-2019/fhv_tripdata_2019-06.parquet\")\n",
    "df_jun.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jun.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jun['PUlocationID'] = pd.to_numeric(df_jun['PUlocationID'], downcast='float')\n",
    "df_jun['DOlocationID'] = pd.to_numeric(df_jun['DOlocationID'], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    #staging='filesystem',\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "\n",
    "load_info = pipeline.run(df_jun, loader_file_format=\"parquet\", table_name=\"fhv_tripdata_2019\", write_disposition=\"append\")\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "table = pq.read_table(\"/Users/nevenkalukic/code/dlt-workshop/fhv-tripdata-2019/fhv_tripdata_2019-12.parquet\")\n",
    "df_fhv = table.filter(\n",
    "    pc.less_equal(table[\"dropOff_datetime\"], pa.scalar(pd.Timestamp.max))\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"taxi_rides_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    #staging='filesystem',\n",
    "    dataset_name=\"taxi_rides_all\"\n",
    ")\n",
    "\n",
    "\n",
    "load_info = pipeline.run(df_fhv, loader_file_format=\"parquet\", table_name=\"fhv_tripdata_2019\", write_disposition=\"append\")\n",
    "print(load_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
